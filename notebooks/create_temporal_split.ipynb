{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            site    label      date    filename  \\\n",
      "0  cheeca_flkeys  healthy  20230504  loc005.tif   \n",
      "1  cheeca_flkeys  healthy  20230504  loc002.tif   \n",
      "2  cheeca_flkeys  healthy  20230504  loc003.tif   \n",
      "3  cheeca_flkeys  healthy  20230504  loc004.tif   \n",
      "4  cheeca_flkeys  healthy  20230504  loc006.tif   \n",
      "\n",
      "                                            filepath  \n",
      "0  /mnt/class_data/group3_remotesensing/mariamaya...  \n",
      "1  /mnt/class_data/group3_remotesensing/mariamaya...  \n",
      "2  /mnt/class_data/group3_remotesensing/mariamaya...  \n",
      "3  /mnt/class_data/group3_remotesensing/mariamaya...  \n",
      "4  /mnt/class_data/group3_remotesensing/mariamaya...  \n",
      "CSV file saved to: /home/Mariam/codes/ct_classifier/runs/resnet18/split_temporal/all.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "##rename to Temporal Split\n",
    "\n",
    "# Base directory\n",
    "datadir = \"/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove\"\n",
    "sites = ['cheeca_flkeys','lbcaye_bbr', 'sanagustin_mexico','northpoint_lizard']\n",
    "#sample_sites= for each site 1 timestamp picked at random\n",
    "\n",
    "# Variables to store file paths and their labels\n",
    "filepaths = []\n",
    "\n",
    "# Collect filepaths from every image that we have\n",
    "for site in sites:    \n",
    "    # Get all bleached and healthy files for the current site\n",
    "    filepaths_site = glob.glob(os.path.join(datadir, site, '**/*.tif'), recursive=True)\n",
    "    # Add filepaths\n",
    "    filepaths.extend(filepaths_site)\n",
    "\n",
    "# Check if files were collected\n",
    "assert filepaths, \"No files found. Please check your directory structure and file paths.\"\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'filepath': filepaths,\n",
    "})\n",
    "\n",
    "# Extract components from the file path\n",
    "df['site'] = df['filepath'].apply(lambda x: x.split('/')[6])  # Extract site\n",
    "df['label'] = df['filepath'].apply(lambda x: x.split('/')[7])  # Extract label (bleached/healthy)\n",
    "df['date'] = df['filepath'].apply(lambda x: x.split('/')[9])  # Extract date\n",
    "df['filename'] = df['filepath'].apply(lambda x: os.path.basename(x))  # Extract filename\n",
    "\n",
    "# Rearrange the columns\n",
    "df = df[['site', 'label', 'date', 'filename', 'filepath']]\n",
    "\n",
    "# Debugging: Check the DataFrame\n",
    "print(df.head())\n",
    "df['image_id'] = range(len(df))\n",
    "# Save all filepaths to CSV\n",
    "output_csv_path = \"/home/Mariam/codes/ct_classifier/runs/resnet18/split_temporal/all.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"CSV file saved to: {output_csv_path}\")\n",
    "\n",
    "# Start creating the data splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list of dictionaries to store filepaths \n",
    "#  of healthy and bleached images\n",
    "val_filepaths = {\n",
    "    'bleached': [],\n",
    "    'healthy': []\n",
    "}\n",
    "test_filepaths = {\n",
    "    'bleached': [],\n",
    "    'healthy': []\n",
    "}\n",
    "train_filepaths = {\n",
    "    'bleached': [],\n",
    "    'healthy': []\n",
    "}\n",
    "\n",
    "excluded_filepaths = []\n",
    "\n",
    "for split_filepaths in [val_filepaths, test_filepaths]:\n",
    "    # Exclude all filepaths that have already been used for other splits\n",
    "    if excluded_filepaths:\n",
    "        df_sub = df[~(df.filepath.isin(excluded_filepaths))]\n",
    "    else:\n",
    "        df_sub = df\n",
    "    \n",
    "    # Select one date at random from every site\n",
    "    for label in ['healthy', 'bleached']:\n",
    "        for site in sites:\n",
    "            # Within all healthy or bleached images, get all dates for the selected site\n",
    "            dates_at_site = df_sub[(df_sub.site==site) & (df_sub.label==label)].date.unique()\n",
    "            # Select one random date within those\n",
    "            random_date = np.random.choice(dates_at_site)\n",
    "            # Get filepaths of all tile locations within selected site and date\n",
    "            filepaths_at_site_date = df_sub[(df_sub.site==site) & (df_sub.date==random_date)].filepath\n",
    "            # Add filepaths to list\n",
    "            split_filepaths[label].extend(filepaths_at_site_date)\n",
    "        \n",
    "        # Add filepaths that we just selected for the test or val split to the list\n",
    "        # of excluded files\n",
    "        excluded_filepaths.extend(split_filepaths[label])\n",
    "\n",
    "# Move all else into train split\n",
    "df_train = df[~(df.filepath.isin(excluded_filepaths))]\n",
    "for label in ['healthy', 'bleached']:\n",
    "    train_filepaths[label] = list(df_train[df_train.label==label].filepath.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exlcluded filepaths: 43\n",
      "Bleached: 11 Healthy: 10 Bleached: 11 Healthy: 11\n",
      "Bleached train: 70\n",
      "69\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "# todo: debug case in which there s a site that has less than 3 dates and\\or theres an unequal number of bleached\\\\ healhty images\n",
    "print('Exlcluded filepaths:',len(excluded_filepaths))\n",
    "print('Bleached:',len(test_filepaths['bleached']), 'Healthy:', len(test_filepaths['healthy']), 'Bleached:', len(val_filepaths['bleached']), 'Healthy:',len(val_filepaths['healthy']))\n",
    "\n",
    "print('Bleached train:', len(train_filepaths['bleached']))\n",
    "print(len(train_filepaths['healthy']))\n",
    "print(len(df) )\n",
    "assert (len(df) == len(test_filepaths['bleached']) + \n",
    "    len(test_filepaths['healthy']) +len(val_filepaths['bleached']) + \n",
    "    len(val_filepaths['healthy']) + len(train_filepaths['bleached']) + \n",
    "    len(train_filepaths['healthy'])), 'For some unknown reason the '\\\n",
    "    'total number images in each split does not equal the number of file that we have'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230805/loc005.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230805/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230805/loc003.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230805/loc004.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230805/loc006.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230805/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230730/loc005.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230730/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230730/loc003.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230730/loc004.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230730/loc006.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230730/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230826/loc005.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230826/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230826/loc003.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230826/loc004.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230826/loc006.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230826/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc_006.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc_005.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc_004.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc_003.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc_001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc_002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230825/loc_006.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230825/loc_005.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230825/loc_004.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230825/loc_003.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230825/loc_001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230825/loc_002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230806/loc_006.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230806/loc_005.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230806/loc_004.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230806/loc_003.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230806/loc_001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230806/loc_002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/lbcaye_bbr/bleached/tiled_360m/20240929/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/lbcaye_bbr/bleached/tiled_360m/20240929/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230723/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230723/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230731/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230731/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230721/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230721/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230727/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230727/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230713/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230713/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230711/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230711/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230720/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230720/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230705/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230705/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230708/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230708/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240326/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240327/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240401/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240226/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240313/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240330/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240403/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240308/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240314/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240319/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240312/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240331/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240315/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240229/loc001.tif']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = train_filepaths['bleached'] + train_filepaths['healthy']\n",
    "val_files = val_filepaths['bleached'] + val_filepaths['healthy']+test_filepaths['bleached'] + test_filepaths['healthy']\n",
    "train_df = df.query('filepath in @train_files')\n",
    "val_df = df.query('filepath in @val_files')\n",
    "val_df.to_csv('/home/Mariam/codes/ct_classifier/data/split_temporal/val.csv')\n",
    "train_df.to_csv('/home/Mariam/codes/ct_classifier/data/split_temporal/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_df = df.query('filepath in @temp_files')\n",
    "#train_df = df.query('filepath in @temp_files')\n",
    "#train_df['image_id'] = range(len(train_df))\n",
    "val_df = pd.read_csv('/home/Mariam/codes/ct_classifier/data/split_temporal/val.csv')\n",
    "\n",
    "sites = val_df.site.unique()\n",
    "image_couples = []\n",
    "couple_labels = []\n",
    "for site in sites:\n",
    "    site_df = val_df[val_df.site==site]\n",
    "    locations = site_df.filename.unique()\n",
    "    for location_name in locations:\n",
    "        #location_name = locations[0]\n",
    "        location_df = site_df[site_df.filename == location_name]\n",
    "        healthy_df = location_df[location_df.label=='healthy']\n",
    "        for i, healthy_entry in healthy_df.iterrows(): # go over all healthy image within a specific location within a specific site\n",
    "            for j, query_entry in location_df.iterrows(): # match them with any other image from that location in that site (aside from themselves)\n",
    "                if healthy_entry.image_id != query_entry.image_id:\n",
    "                    new_couple = (healthy_entry.image_id, query_entry.image_id) # create new image pair of one healthy image and another query\n",
    "                    new_label = query_entry.label\n",
    "                    image_couples.append(new_couple)\n",
    "                    couple_labels.append(new_label)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "bleached    30\n",
       "healthy     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ds = pd.DataFrame({'couple':image_couples, 'label':couple_labels})\n",
    "p_ds.label.value_counts()\n",
    "#len(set(image_couples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>site</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>151</td>\n",
       "      <td>northpoint_lizard</td>\n",
       "      <td>healthy</td>\n",
       "      <td>20230911</td>\n",
       "      <td>loc001.tif</td>\n",
       "      <td>/mnt/class_data/group3_remotesensing/mariamaya...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>165</td>\n",
       "      <td>northpoint_lizard</td>\n",
       "      <td>healthy</td>\n",
       "      <td>20230914</td>\n",
       "      <td>loc001.tif</td>\n",
       "      <td>/mnt/class_data/group3_remotesensing/mariamaya...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>174</td>\n",
       "      <td>northpoint_lizard</td>\n",
       "      <td>bleached</td>\n",
       "      <td>20240404</td>\n",
       "      <td>loc001.tif</td>\n",
       "      <td>/mnt/class_data/group3_remotesensing/mariamaya...</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>177</td>\n",
       "      <td>northpoint_lizard</td>\n",
       "      <td>bleached</td>\n",
       "      <td>20240323</td>\n",
       "      <td>loc001.tif</td>\n",
       "      <td>/mnt/class_data/group3_remotesensing/mariamaya...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0               site     label      date    filename  \\\n",
       "39         151  northpoint_lizard   healthy  20230911  loc001.tif   \n",
       "40         165  northpoint_lizard   healthy  20230914  loc001.tif   \n",
       "41         174  northpoint_lizard  bleached  20240404  loc001.tif   \n",
       "42         177  northpoint_lizard  bleached  20240323  loc001.tif   \n",
       "\n",
       "                                             filepath  image_id  \n",
       "39  /mnt/class_data/group3_remotesensing/mariamaya...       151  \n",
       "40  /mnt/class_data/group3_remotesensing/mariamaya...       165  \n",
       "41  /mnt/class_data/group3_remotesensing/mariamaya...       174  \n",
       "42  /mnt/class_data/group3_remotesensing/mariamaya...       177  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in PROJ: internal_proj_create_from_database: /home/Mariam/miniconda3/envs/cv4ecology/share/proj/proj.db contains DATABASE.LAYOUT.VERSION.MINOR = 2 whereas a number >= 3 is expected. It comes from another PROJ installation.\n",
      "WARNING:rasterio._env:CPLE_AppDefined in The definition of projected CRS EPSG:32617 got from GeoTIFF keys is not the same as the one from the EPSG registry, which may cause issues during reprojection operations. Set GTIFF_SRS_SOURCE configuration option to EPSG to use official parameters (overriding the ones from GeoTIFF keys), or to GEOKEYS to use custom values from GeoTIFF keys and drop the EPSG code.\n",
      "WARNING:rasterio._env:CPLE_AppDefined in PROJ: internal_proj_create_from_database: /home/Mariam/miniconda3/envs/cv4ecology/share/proj/proj.db contains DATABASE.LAYOUT.VERSION.MINOR = 2 whereas a number >= 3 is expected. It comes from another PROJ installation.\n",
      "WARNING:rasterio._env:CPLE_AppDefined in The definition of projected CRS EPSG:32617 got from GeoTIFF keys is not the same as the one from the EPSG registry, which may cause issues during reprojection operations. Set GTIFF_SRS_SOURCE configuration option to EPSG to use official parameters (overriding the ones from GeoTIFF keys), or to GEOKEYS to use custom values from GeoTIFF keys and drop the EPSG code.\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import torch\n",
    "couple = image_couples[0]\n",
    "idxs = couple\n",
    "imgs = []\n",
    "for idx in idxs:\n",
    "    filepath = val_df.query('image_id==@idx').filepath.values[0]\n",
    "    with rasterio.open(filepath, mode='r') as ds:\n",
    "        img = ds.read()\n",
    "    imgs.append(img)\n",
    "#filepath2 = val_df.query('image_id==@image_idx2').filepath.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 132, 133)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.concatenate(imgs)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 120, 120])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kornia.augmentation import Resize\n",
    "r = Resize((120,120),align_corners=False)\n",
    "r(torch.tensor(img,dtype=torch.float64)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/Mariam/codes/ct_classifier/ct_classifier')\n",
    "from dataset import BleachDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from train import create_dataloader\n",
    "cfg = yaml.safe_load(open('/home/Mariam/codes/ct_classifier/configs/exp_resnet18.yaml', 'r'))\n",
    "dl_train = create_dataloader(cfg, split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch = next(iter(dl_train))\n",
    "#batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Display the first image couple from image_couples\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m couple \u001b[38;5;241m=\u001b[39m \u001b[43mimage_couples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m53\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     68\u001b[0m idxs \u001b[38;5;241m=\u001b[39m couple\n\u001b[1;32m     69\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [val_df\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_id==@idx\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idxs]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to mask no-data values and display the image\n",
    "def mask_nodata_and_show(filepath, nodata_value=None):\n",
    "    with rasterio.open(filepath, mode='r') as ds:\n",
    "        img = ds.read([2, 4, 6])  # Read blue, green, and red bands (2, 4, 6)\n",
    "        \n",
    "        # Apply the mask based on the no-data value (if provided)\n",
    "        if nodata_value is None:\n",
    "            nodata_value = ds.nodata  # Get the default no-data value from the file\n",
    "            \n",
    "        mask = np.ma.masked_equal(img, nodata_value)  # Mask the no-data value\n",
    "\n",
    "        # Normalize and display the image\n",
    "        img_normalized = np.stack([np.clip((band - band.min()) / (band.max() - band.min()), 0, 1) for band in mask], axis=-1)\n",
    "\n",
    "        # Display the image\n",
    "        plt.imshow(img_normalized)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        #####\n",
    "\n",
    "        \n",
    "# Function to normalize the image band using percentiles (2nd and 98th percentiles)\n",
    "def percentile_normalize_image_band(band, lower_percentile=2, upper_percentile=98):\n",
    "    lower = np.percentile(band, lower_percentile)\n",
    "    upper = np.percentile(band, upper_percentile)\n",
    "    # Normalize by clipping the values between the lower and upper percentiles and then scaling to [0, 1]\n",
    "    normalized_band = np.clip((band - lower) / (upper - lower), 0, 1)\n",
    "    return normalized_band\n",
    "\n",
    "# Function to read and display the images side by side with custom band order\n",
    "def show_image_pair(image_paths):\n",
    "    imgs = []\n",
    "    for path in image_paths:\n",
    "        with rasterio.open(path, mode='r') as ds:\n",
    "            # Read specific bands: blue (2), green (4), red (6)\n",
    "            blue_band = ds.read(2)  # Band 2: Blue\n",
    "            green_band = ds.read(4)  # Band 4: Green\n",
    "            red_band = ds.read(6)  # Band 6: Red\n",
    "\n",
    "            # Apply percentile normalization to each band\n",
    "            blue_band = percentile_normalize_image_band(blue_band)\n",
    "            green_band = percentile_normalize_image_band(green_band)\n",
    "            red_band = percentile_normalize_image_band(red_band)\n",
    "\n",
    "            # Stack bands into an RGB image\n",
    "            #img = np.stack((blue_band, green_band, red_band), axis=-1)\n",
    "            img = np.stack((red_band, green_band, blue_band), axis=-1)\n",
    "            imgs.append(img)\n",
    "    \n",
    "    # Display images side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(imgs[0])\n",
    "    axes[0].set_title('Healthy Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(imgs[1])\n",
    "    axes[1].set_title('Query Image')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Display the first image couple from image_couples\n",
    "couple = image_couples[53]\n",
    "idxs = couple\n",
    "image_paths = [val_df.query('image_id==@idx').filepath.values[0] for idx in idxs]\n",
    "show_image_pair(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4ecology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
