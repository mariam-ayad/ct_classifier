{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            site    label      date    filename  \\\n",
      "0  cheeca_flkeys  healthy  20230504  loc005.tif   \n",
      "1  cheeca_flkeys  healthy  20230504  loc002.tif   \n",
      "2  cheeca_flkeys  healthy  20230504  loc003.tif   \n",
      "3  cheeca_flkeys  healthy  20230504  loc004.tif   \n",
      "4  cheeca_flkeys  healthy  20230504  loc006.tif   \n",
      "\n",
      "                                            filepath  \n",
      "0  /mnt/class_data/group3_remotesensing/mariamaya...  \n",
      "1  /mnt/class_data/group3_remotesensing/mariamaya...  \n",
      "2  /mnt/class_data/group3_remotesensing/mariamaya...  \n",
      "3  /mnt/class_data/group3_remotesensing/mariamaya...  \n",
      "4  /mnt/class_data/group3_remotesensing/mariamaya...  \n",
      "CSV file saved to: /home/Mariam/codes/ct_classifier/runs/resnet18/split_temporal/all.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "##rename to Temporal Split\n",
    "\n",
    "# Base directory\n",
    "datadir = \"/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove\"\n",
    "sites = ['cheeca_flkeys','lbcaye_bbr', 'sanagustin_mexico','northpoint_lizard']\n",
    "#sample_sites= for each site 1 timestamp picked at random\n",
    "\n",
    "# Variables to store file paths and their labels\n",
    "filepaths = []\n",
    "\n",
    "# Collect filepaths from every image that we have\n",
    "for site in sites:    \n",
    "    # Get all bleached and healthy files for the current site\n",
    "    filepaths_site = glob.glob(os.path.join(datadir, site, '**/*.tif'), recursive=True)\n",
    "    # Add filepaths\n",
    "    filepaths.extend(filepaths_site)\n",
    "\n",
    "# Check if files were collected\n",
    "assert filepaths, \"No files found. Please check your directory structure and file paths.\"\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'filepath': filepaths,\n",
    "})\n",
    "\n",
    "# Extract components from the file path\n",
    "df['site'] = df['filepath'].apply(lambda x: x.split('/')[6])  # Extract site\n",
    "df['label'] = df['filepath'].apply(lambda x: x.split('/')[7])  # Extract label (bleached/healthy)\n",
    "df['date'] = df['filepath'].apply(lambda x: x.split('/')[9])  # Extract date\n",
    "df['filename'] = df['filepath'].apply(lambda x: os.path.basename(x))  # Extract filename\n",
    "\n",
    "# Rearrange the columns\n",
    "df = df[['site', 'label', 'date', 'filename', 'filepath']]\n",
    "\n",
    "# Debugging: Check the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save all filepaths to CSV\n",
    "output_csv_path = \"/home/Mariam/codes/ct_classifier/runs/resnet18/split_temporal/all.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"CSV file saved to: {output_csv_path}\")\n",
    "\n",
    "# Start creating the data splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list of dictionaries to store filepaths \n",
    "#  of healthy and bleached images\n",
    "val_filepaths = {\n",
    "    'bleached': [],\n",
    "    'healthy': []\n",
    "}\n",
    "test_filepaths = {\n",
    "    'bleached': [],\n",
    "    'healthy': []\n",
    "}\n",
    "train_filepaths = {\n",
    "    'bleached': [],\n",
    "    'healthy': []\n",
    "}\n",
    "\n",
    "excluded_filepaths = []\n",
    "\n",
    "for split_filepaths in [val_filepaths, test_filepaths]:\n",
    "    # Exclude all filepaths that have already been used for other splits\n",
    "    if excluded_filepaths:\n",
    "        df_sub = df[~(df.filepath.isin(excluded_filepaths))]\n",
    "    else:\n",
    "        df_sub = df\n",
    "    \n",
    "    # Select one date at random from every site\n",
    "    for label in ['healthy', 'bleached']:\n",
    "        for site in sites:\n",
    "            # Within all healthy or bleached images, get all dates for the selected site\n",
    "            dates_at_site = df_sub[(df_sub.site==site) & (df_sub.label==label)].date.unique()\n",
    "            # Select one random date within those\n",
    "            random_date = np.random.choice(dates_at_site)\n",
    "            # Get filepaths of all tile locations within selected site and date\n",
    "            filepaths_at_site_date = df_sub[(df_sub.site==site) & (df_sub.date==random_date)].filepath\n",
    "            # Add filepaths to list\n",
    "            split_filepaths[label].extend(filepaths_at_site_date)\n",
    "        \n",
    "        # Add filepaths that we just selected for the test or val split to the list\n",
    "        # of excluded files\n",
    "        excluded_filepaths.extend(split_filepaths[label])\n",
    "\n",
    "# Move all else into train split\n",
    "df_train = df[~(df.filepath.isin(excluded_filepaths))]\n",
    "for label in ['healthy', 'bleached']:\n",
    "    train_filepaths[label] = df_train[df_train.label==label].filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "11 11 11 11\n",
      "70\n",
      "68\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "# todo: debug case in which there s a site that has less than 3 dates and\\or theres an unequal number of bleached\\\\ healhty images\n",
    "print(len(excluded_filepaths))\n",
    "print(len(test_filepaths['bleached']), len(test_filepaths['healthy']), len(val_filepaths['bleached']), len(val_filepaths['healthy']))\n",
    "\n",
    "print(len(train_filepaths['bleached']))\n",
    "print(len(train_filepaths['healthy']))\n",
    "print(len(df) )\n",
    "assert (len(df) == len(test_filepaths['bleached']) + \n",
    "    len(test_filepaths['healthy']) +len(val_filepaths['bleached']) + \n",
    "    len(val_filepaths['healthy']) + len(train_filepaths['bleached']) + \n",
    "    len(train_filepaths['healthy'])), 'For some unknown reason the '\\\n",
    "    'total number images in each split does not equal the number of file that we have'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc005.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc003.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc004.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc006.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/cheeca_flkeys/bleached/tiled_360m/20230817/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/lbcaye_bbr/bleached/tiled_360m/20240929/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/lbcaye_bbr/bleached/tiled_360m/20240929/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230720/loc002.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/sanagustin_mexico/bleached/tiled_360m/20230720/loc001.tif',\n",
       " '/mnt/class_data/group3_remotesensing/mariamayad/planet_superdove/northpoint_lizard/bleached/tiled_360m/20240319/loc001.tif']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_filepaths[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4ecology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
